"""
Resource Pooling MCP Pattern

This pattern manages a pool of reusable resources to improve performance and
reduce overhead by reusing existing resources instead of creating new ones.

Key Features:
- Resource pool management
- Efficient allocation and deallocation
- Resource lifecycle tracking
- Pool size management
- Resource health monitoring
"""

from typing import TypedDict, Sequence, Annotated, List, Dict
import operator
import time
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, SystemMessage, AIMessage
from langgraph.graph import StateGraph, START, END


# Define the state
class ResourcePoolState(TypedDict):
    """State for resource pooling pattern"""
    messages: Annotated[Sequence[HumanMessage | SystemMessage | AIMessage], operator.add]
    pool_name: str
    resource_type: str  # "database", "thread", "connection", "worker"
    pool_size: int
    min_pool_size: int
    max_pool_size: int
    available_resources: int
    in_use_resources: int
    resource_requests: int
    pool_utilization: float  # 0.0 to 1.0
    resource_health: Dict[str, str]  # resource_id -> "healthy", "degraded", "failed"
    wait_time: float  # average wait time for resource acquisition
    allocation_strategy: str  # "fifo", "lifo", "least_used", "round_robin"


# Initialize LLM
llm = ChatOpenAI(model="gpt-4", temperature=0)


# Pool Manager
def pool_manager(state: ResourcePoolState) -> ResourcePoolState:
    """Manages resource pool initialization and sizing"""
    pool_name = state.get("pool_name", "")
    resource_type = state.get("resource_type", "")
    min_pool_size = state.get("min_pool_size", 5)
    max_pool_size = state.get("max_pool_size", 20)
    
    system_message = SystemMessage(content="""You are a resource pool manager. 
    Initialize and manage pools of reusable resources for optimal performance.""")
    
    user_message = HumanMessage(content=f"""Manage resource pool:

Pool Name: {pool_name}
Resource Type: {resource_type}
Min Pool Size: {min_pool_size}
Max Pool Size: {max_pool_size}

Initialize and configure resource pool.""")
    
    response = llm.invoke([system_message, user_message])
    
    # Initialize pool with minimum resources
    pool_size = min_pool_size
    available_resources = min_pool_size
    in_use_resources = 0
    
    # Create initial resource health tracking
    resource_health = {}
    for i in range(pool_size):
        resource_id = f"{pool_name}_resource_{i+1}"
        resource_health[resource_id] = "healthy"
    
    pool_utilization = 0.0  # No resources in use initially
    
    pool_report = f"""
    üèä Resource Pool Management:
    
    Pool Configuration:
    ‚Ä¢ Pool Name: {pool_name}
    ‚Ä¢ Resource Type: {resource_type}
    ‚Ä¢ Current Size: {pool_size}
    ‚Ä¢ Min Size: {min_pool_size}
    ‚Ä¢ Max Size: {max_pool_size}
    
    Resource Status:
    ‚Ä¢ Available: {available_resources}
    ‚Ä¢ In Use: {in_use_resources}
    ‚Ä¢ Utilization: {pool_utilization:.1%}
    ‚Ä¢ Health Status: {len([h for h in resource_health.values() if h == 'healthy'])} healthy
    
    Resource Pooling Benefits:
    
    Performance:
    ‚Ä¢ Reduced creation overhead
    ‚Ä¢ Faster resource acquisition
    ‚Ä¢ Improved response times
    ‚Ä¢ Lower latency
    ‚Ä¢ Better throughput
    
    Resource Efficiency:
    ‚Ä¢ Reuse existing resources
    ‚Ä¢ Limit resource creation
    ‚Ä¢ Controlled resource count
    ‚Ä¢ Prevent resource exhaustion
    ‚Ä¢ Optimize resource usage
    
    Scalability:
    ‚Ä¢ Handle traffic spikes
    ‚Ä¢ Dynamic pool sizing
    ‚Ä¢ Load distribution
    ‚Ä¢ Graceful degradation
    ‚Ä¢ Elastic scaling
    
    Pool Management Strategies:
    
    Sizing:
    ‚Ä¢ Min pool size: Always available resources
    ‚Ä¢ Max pool size: Resource cap limit
    ‚Ä¢ Dynamic sizing: Grow/shrink based on demand
    ‚Ä¢ Idle timeout: Return unused resources
    
    Allocation:
    ‚Ä¢ FIFO: First in, first out
    ‚Ä¢ LIFO: Last in, first out
    ‚Ä¢ Least Used: Balance wear
    ‚Ä¢ Round Robin: Even distribution
    
    Health Management:
    ‚Ä¢ Health checks before allocation
    ‚Ä¢ Automatic resource replacement
    ‚Ä¢ Graceful degradation
    ‚Ä¢ Circuit breaker integration
    
    Pool Types:
    
    Database Connection Pool:
    ‚Ä¢ Reuse DB connections
    ‚Ä¢ Reduce connection overhead
    ‚Ä¢ Limit concurrent connections
    ‚Ä¢ Connection validation
    ‚Ä¢ Statement caching
    
    Thread Pool:
    ‚Ä¢ Worker thread reuse
    ‚Ä¢ Task queue processing
    ‚Ä¢ Thread lifecycle management
    ‚Ä¢ Work stealing
    ‚Ä¢ Priority queues
    
    Object Pool:
    ‚Ä¢ Expensive object reuse
    ‚Ä¢ Memory allocation reduction
    ‚Ä¢ Object lifecycle management
    ‚Ä¢ State reset between uses
    
    HTTP Connection Pool:
    ‚Ä¢ Keep-alive connections
    ‚Ä¢ SSL/TLS session reuse
    ‚Ä¢ DNS caching
    ‚Ä¢ Connection pipelining
    
    Resource Pool Lifecycle:
    
    1. Initialization:
       ‚Ä¢ Create minimum resources
       ‚Ä¢ Validate resources
       ‚Ä¢ Mark as available
    
    2. Acquisition:
       ‚Ä¢ Check for available resource
       ‚Ä¢ Validate resource health
       ‚Ä¢ Mark as in-use
       ‚Ä¢ Return to requester
    
    3. Usage:
       ‚Ä¢ Resource performs work
       ‚Ä¢ Monitor resource health
       ‚Ä¢ Track usage metrics
    
    4. Release:
       ‚Ä¢ Return to pool
       ‚Ä¢ Reset resource state
       ‚Ä¢ Mark as available
       ‚Ä¢ Health check
    
    5. Cleanup:
       ‚Ä¢ Remove unhealthy resources
       ‚Ä¢ Shrink pool if needed
       ‚Ä¢ Close idle resources
       ‚Ä¢ Free memory
    
    Configuration Best Practices:
    ‚Ä¢ Set appropriate min/max sizes
    ‚Ä¢ Monitor pool metrics
    ‚Ä¢ Tune based on workload
    ‚Ä¢ Implement health checks
    ‚Ä¢ Use timeout mechanisms
    ‚Ä¢ Handle resource exhaustion
    ‚Ä¢ Log pool statistics
    """
    
    return {
        "messages": [AIMessage(content=f"üèä Pool Manager:\n{response.content}\n{pool_report}")],
        "pool_size": pool_size,
        "available_resources": available_resources,
        "in_use_resources": in_use_resources,
        "pool_utilization": pool_utilization,
        "resource_health": resource_health
    }


# Resource Allocator
def resource_allocator(state: ResourcePoolState) -> ResourcePoolState:
    """Allocates resources from the pool"""
    pool_name = state.get("pool_name", "")
    available_resources = state.get("available_resources", 0)
    pool_size = state.get("pool_size", 0)
    max_pool_size = state.get("max_pool_size", 20)
    resource_requests = state.get("resource_requests", 5)  # Simulated requests
    allocation_strategy = state.get("allocation_strategy", "fifo")
    
    system_message = SystemMessage(content="""You are a resource allocator. 
    Efficiently allocate resources from the pool to satisfy requests.""")
    
    user_message = HumanMessage(content=f"""Allocate resources:

Pool: {pool_name}
Available Resources: {available_resources}
Pool Size: {pool_size}
Max Pool Size: {max_pool_size}
Pending Requests: {resource_requests}
Strategy: {allocation_strategy}

Allocate resources to requests.""")
    
    response = llm.invoke([system_message, user_message])
    
    # Simulate resource allocation
    resources_to_allocate = min(resource_requests, available_resources)
    
    # If no resources available but can grow pool
    if resources_to_allocate == 0 and pool_size < max_pool_size:
        # Grow pool
        growth = min(resource_requests, max_pool_size - pool_size)
        pool_size += growth
        available_resources += growth
        resources_to_allocate = min(resource_requests, available_resources)
        pool_grown = True
    else:
        pool_grown = False
    
    # Allocate resources
    allocated = resources_to_allocate
    available_resources -= allocated
    in_use_resources = state.get("in_use_resources", 0) + allocated
    
    # Calculate wait time (if requests > available)
    wait_time = 0.0
    if resource_requests > resources_to_allocate:
        # Some requests had to wait
        wait_time = (resource_requests - resources_to_allocate) * 0.1  # Simulated
    
    # Calculate pool utilization
    pool_utilization = in_use_resources / pool_size if pool_size > 0 else 0.0
    
    allocation_report = f"""
    üì§ Resource Allocation:
    
    Allocation Results:
    ‚Ä¢ Requests: {resource_requests}
    ‚Ä¢ Allocated: {allocated}
    ‚Ä¢ Queued/Rejected: {resource_requests - allocated}
    ‚Ä¢ Success Rate: {(allocated/resource_requests*100) if resource_requests > 0 else 0:.1f}%
    
    Pool Status After Allocation:
    ‚Ä¢ Total Pool Size: {pool_size}
    ‚Ä¢ Available: {available_resources}
    ‚Ä¢ In Use: {in_use_resources}
    ‚Ä¢ Utilization: {pool_utilization:.1%}
    {f'‚Ä¢ Pool Grown: +{growth} resources' if pool_grown else ''}
    
    Performance Metrics:
    ‚Ä¢ Average Wait Time: {wait_time:.3f}s
    ‚Ä¢ Allocation Strategy: {allocation_strategy.upper()}
    
    Allocation Strategies:
    
    FIFO (First-In-First-Out):
    ‚Ä¢ Fair allocation order
    ‚Ä¢ Simple to implement
    ‚Ä¢ No resource starvation
    ‚Ä¢ Predictable behavior
    
    LIFO (Last-In-First-Out):
    ‚Ä¢ Hot resource reuse
    ‚Ä¢ Better cache locality
    ‚Ä¢ May cause starvation
    ‚Ä¢ Stack-based allocation
    
    Least Used:
    ‚Ä¢ Balance resource wear
    ‚Ä¢ Extend resource lifetime
    ‚Ä¢ Even usage distribution
    ‚Ä¢ Health-aware allocation
    
    Round Robin:
    ‚Ä¢ Circular allocation
    ‚Ä¢ Even distribution
    ‚Ä¢ Simple load balancing
    ‚Ä¢ Predictable pattern
    
    Priority-Based:
    ‚Ä¢ VIP request handling
    ‚Ä¢ Critical workload first
    ‚Ä¢ Service level objectives
    ‚Ä¢ Multi-tier allocation
    
    Allocation Scenarios:
    
    High Demand (Requests > Available):
    ‚Ä¢ Queue excess requests
    ‚Ä¢ Grow pool if possible
    ‚Ä¢ Apply backpressure
    ‚Ä¢ Reject with timeout
    ‚Ä¢ Shed load if needed
    
    Normal Load:
    ‚Ä¢ Direct allocation
    ‚Ä¢ Minimal wait time
    ‚Ä¢ Optimal utilization
    ‚Ä¢ Stable performance
    
    Low Demand (Available > In-Use):
    ‚Ä¢ Immediate allocation
    ‚Ä¢ Consider pool shrinking
    ‚Ä¢ Idle timeout cleanup
    ‚Ä¢ Resource conservation
    
    Resource Exhaustion:
    ‚Ä¢ All resources in use
    ‚Ä¢ Pool at maximum
    ‚Ä¢ Queue requests
    ‚Ä¢ Apply timeout
    ‚Ä¢ Alternative: rejection
    
    Dynamic Pool Sizing:
    
    Growing Conditions:
    ‚Ä¢ High utilization (>80%)
    ‚Ä¢ Frequent queuing
    ‚Ä¢ Sustained demand
    ‚Ä¢ Below max pool size
    
    Shrinking Conditions:
    ‚Ä¢ Low utilization (<20%)
    ‚Ä¢ Idle resources
    ‚Ä¢ Above min pool size
    ‚Ä¢ Resource cost reduction
    
    Allocation Failure Handling:
    ‚Ä¢ Request queuing
    ‚Ä¢ Timeout mechanisms
    ‚Ä¢ Graceful degradation
    ‚Ä¢ Error responses
    ‚Ä¢ Retry logic
    ‚Ä¢ Circuit breaker
    """
    
    return {
        "messages": [AIMessage(content=f"üì§ Resource Allocator:\n{response.content}\n{allocation_report}")],
        "pool_size": pool_size,
        "available_resources": available_resources,
        "in_use_resources": in_use_resources,
        "pool_utilization": pool_utilization,
        "wait_time": wait_time
    }


# Health Monitor
def health_monitor(state: ResourcePoolState) -> ResourcePoolState:
    """Monitors resource health and performs maintenance"""
    pool_name = state.get("pool_name", "")
    resource_health = state.get("resource_health", {})
    pool_size = state.get("pool_size", 0)
    
    system_message = SystemMessage(content="""You are a resource health monitor. 
    Monitor resource health, detect failures, and maintain pool quality.""")
    
    user_message = HumanMessage(content=f"""Monitor resource health:

Pool: {pool_name}
Pool Size: {pool_size}
Resources Tracked: {len(resource_health)}

Perform health checks and maintenance.""")
    
    response = llm.invoke([system_message, user_message])
    
    # Simulate health checks
    healthy_count = 0
    degraded_count = 0
    failed_count = 0
    
    for resource_id, health in resource_health.items():
        if health == "healthy":
            healthy_count += 1
        elif health == "degraded":
            degraded_count += 1
        else:
            failed_count += 1
    
    # Simulate some resources becoming degraded (random simulation)
    # In production, this would be actual health checks
    import random
    if healthy_count > 0 and random.random() < 0.1:  # 10% chance
        # Mark one resource as degraded
        for resource_id, health in resource_health.items():
            if health == "healthy":
                resource_health[resource_id] = "degraded"
                healthy_count -= 1
                degraded_count += 1
                break
    
    health_percentage = (healthy_count / len(resource_health) * 100) if resource_health else 0
    
    health_report = f"""
    üè• Resource Health Monitoring:
    
    Health Status:
    ‚Ä¢ Healthy: {healthy_count} ({healthy_count/len(resource_health)*100 if resource_health else 0:.1f}%)
    ‚Ä¢ Degraded: {degraded_count}
    ‚Ä¢ Failed: {failed_count}
    ‚Ä¢ Overall Health: {health_percentage:.1f}%
    
    Pool Health Metrics:
    ‚Ä¢ Total Resources: {len(resource_health)}
    ‚Ä¢ Health Check Interval: 30 seconds
    ‚Ä¢ Auto-Replacement: Enabled
    
    Health Monitoring:
    
    Health Check Types:
    
    Passive Checks:
    ‚Ä¢ On resource acquisition
    ‚Ä¢ Before returning to pool
    ‚Ä¢ Lightweight validation
    ‚Ä¢ No overhead when idle
    
    Active Checks:
    ‚Ä¢ Periodic background checks
    ‚Ä¢ Proactive detection
    ‚Ä¢ All resources checked
    ‚Ä¢ Scheduled intervals
    
    Deep Checks:
    ‚Ä¢ Comprehensive validation
    ‚Ä¢ Resource stress testing
    ‚Ä¢ Connection verification
    ‚Ä¢ Performance benchmarking
    
    Health Indicators:
    
    Database Connections:
    ‚Ä¢ Connection validity
    ‚Ä¢ Query execution
    ‚Ä¢ Response time
    ‚Ä¢ Error rate
    ‚Ä¢ Transaction state
    
    Thread Pool:
    ‚Ä¢ Thread state
    ‚Ä¢ CPU usage
    ‚Ä¢ Memory consumption
    ‚Ä¢ Queue depth
    ‚Ä¢ Task completion rate
    
    HTTP Connections:
    ‚Ä¢ Connection state
    ‚Ä¢ Latency
    ‚Ä¢ Error rate
    ‚Ä¢ SSL certificate validity
    ‚Ä¢ DNS resolution
    
    Health States:
    
    Healthy (100%):
    ‚Ä¢ All checks pass
    ‚Ä¢ Normal performance
    ‚Ä¢ Ready for allocation
    ‚Ä¢ No intervention needed
    
    Degraded (50-99%):
    ‚Ä¢ Some checks fail
    ‚Ä¢ Reduced performance
    ‚Ä¢ Still functional
    ‚Ä¢ Monitor closely
    ‚Ä¢ May self-recover
    
    Failed (0-49%):
    ‚Ä¢ Critical checks fail
    ‚Ä¢ Unusable resource
    ‚Ä¢ Remove from pool
    ‚Ä¢ Create replacement
    ‚Ä¢ Investigate cause
    
    Maintenance Actions:
    
    Resource Replacement:
    ‚Ä¢ Remove failed resources
    ‚Ä¢ Create new resources
    ‚Ä¢ Validate new resources
    ‚Ä¢ Add to pool
    ‚Ä¢ Maintain pool size
    
    Resource Repair:
    ‚Ä¢ Attempt recovery
    ‚Ä¢ Reset connections
    ‚Ä¢ Clear state
    ‚Ä¢ Re-validate
    ‚Ä¢ Return to pool
    
    Pool Optimization:
    ‚Ä¢ Remove excess resources
    ‚Ä¢ Balance resource usage
    ‚Ä¢ Defragment pool
    ‚Ä¢ Update configuration
    
    Preventive Maintenance:
    ‚Ä¢ Rotate resources
    ‚Ä¢ Prevent resource aging
    ‚Ä¢ Update credentials
    ‚Ä¢ Refresh certificates
    ‚Ä¢ Clear caches
    
    Health Monitoring Best Practices:
    ‚Ä¢ Regular health checks
    ‚Ä¢ Multiple health indicators
    ‚Ä¢ Automated remediation
    ‚Ä¢ Health metrics logging
    ‚Ä¢ Alert on degradation
    ‚Ä¢ Trend analysis
    ‚Ä¢ Capacity planning
    """
    
    return {
        "messages": [AIMessage(content=f"üè• Health Monitor:\n{response.content}\n{health_report}")],
        "resource_health": resource_health
    }


# Pool Monitor
def pool_monitor(state: ResourcePoolState) -> ResourcePoolState:
    """Monitors overall pool performance and provides insights"""
    pool_name = state.get("pool_name", "")
    resource_type = state.get("resource_type", "")
    pool_size = state.get("pool_size", 0)
    min_pool_size = state.get("min_pool_size", 0)
    max_pool_size = state.get("max_pool_size", 0)
    available_resources = state.get("available_resources", 0)
    in_use_resources = state.get("in_use_resources", 0)
    pool_utilization = state.get("pool_utilization", 0.0)
    wait_time = state.get("wait_time", 0.0)
    resource_health = state.get("resource_health", {})
    
    healthy_count = len([h for h in resource_health.values() if h == "healthy"])
    
    summary = f"""
    üìä RESOURCE POOLING COMPLETE
    
    Pool Summary:
    ‚Ä¢ Pool Name: {pool_name}
    ‚Ä¢ Resource Type: {resource_type}
    ‚Ä¢ Pool Size: {pool_size} (min: {min_pool_size}, max: {max_pool_size})
    
    Resource Status:
    ‚Ä¢ Available: {available_resources}
    ‚Ä¢ In Use: {in_use_resources}
    ‚Ä¢ Utilization: {pool_utilization:.1%}
    ‚Ä¢ Healthy: {healthy_count}/{len(resource_health)}
    
    Performance:
    ‚Ä¢ Average Wait Time: {wait_time:.3f}s
    ‚Ä¢ Health Status: {(healthy_count/len(resource_health)*100) if resource_health else 0:.1f}%
    
    Resource Pooling Pattern Process:
    1. Pool Manager ‚Üí Initialize and configure resource pool
    2. Resource Allocator ‚Üí Allocate resources to requests
    3. Health Monitor ‚Üí Monitor resource health and maintenance
    4. Pool Monitor ‚Üí Track metrics and optimize performance
    
    Resource Pooling Patterns:
    
    Common Pool Implementations:
    
    Apache Commons Pool:
    ‚Ä¢ Java object pooling
    ‚Ä¢ Generic pool framework
    ‚Ä¢ Configurable behaviors
    ‚Ä¢ Factory pattern
    ‚Ä¢ Validation support
    
    HikariCP:
    ‚Ä¢ Fast JDBC connection pool
    ‚Ä¢ Lightweight
    ‚Ä¢ High performance
    ‚Ä¢ JMX monitoring
    ‚Ä¢ Leak detection
    
    C3P0:
    ‚Ä¢ JDBC connection pooling
    ‚Ä¢ Statement caching
    ‚Ä¢ PreparedStatement pooling
    ‚Ä¢ Automatic testing
    ‚Ä¢ Recovery mechanisms
    
    Thread Pool Executor:
    ‚Ä¢ Java concurrent utilities
    ‚Ä¢ Worker thread pool
    ‚Ä¢ Task queue
    ‚Ä¢ Rejection policies
    ‚Ä¢ Thread factory
    
    Pool Configuration Parameters:
    
    Size Configuration:
    ‚Ä¢ minPoolSize: Minimum resources
    ‚Ä¢ maxPoolSize: Maximum resources
    ‚Ä¢ initialPoolSize: Starting resources
    ‚Ä¢ maxIdleTime: Idle resource timeout
    ‚Ä¢ acquireIncrement: Growth increment
    
    Timeout Configuration:
    ‚Ä¢ connectionTimeout: Acquisition timeout
    ‚Ä¢ idleTimeout: Idle before removal
    ‚Ä¢ maxLifetime: Resource lifetime
    ‚Ä¢ keepAliveTime: Thread keep-alive
    
    Validation Configuration:
    ‚Ä¢ testOnBorrow: Validate on acquisition
    ‚Ä¢ testOnReturn: Validate on release
    ‚Ä¢ testWhileIdle: Background validation
    ‚Ä¢ validationQuery: Health check query
    ‚Ä¢ validationTimeout: Check timeout
    
    Pool Metrics to Monitor:
    
    Utilization Metrics:
    ‚Ä¢ Active connections
    ‚Ä¢ Idle connections
    ‚Ä¢ Pool utilization %
    ‚Ä¢ Wait queue length
    ‚Ä¢ Request rate
    
    Performance Metrics:
    ‚Ä¢ Acquisition time
    ‚Ä¢ Wait time
    ‚Ä¢ Throughput
    ‚Ä¢ Error rate
    ‚Ä¢ Timeout rate
    
    Health Metrics:
    ‚Ä¢ Healthy resources
    ‚Ä¢ Failed resources
    ‚Ä¢ Replacement rate
    ‚Ä¢ Validation failures
    
    Resource Metrics:
    ‚Ä¢ Memory usage
    ‚Ä¢ Thread count
    ‚Ä¢ Connection count
    ‚Ä¢ Pool size
    ‚Ä¢ Growth/shrink events
    
    Common Pool Problems:
    
    Pool Exhaustion:
    ‚Ä¢ Symptom: All resources in use
    ‚Ä¢ Cause: Insufficient pool size
    ‚Ä¢ Solution: Increase max pool size
    ‚Ä¢ Prevention: Monitor utilization
    
    Resource Leaks:
    ‚Ä¢ Symptom: Resources not returned
    ‚Ä¢ Cause: Missing finally blocks
    ‚Ä¢ Solution: Automatic cleanup
    ‚Ä¢ Prevention: Proper resource management
    
    Stale Resources:
    ‚Ä¢ Symptom: Failed health checks
    ‚Ä¢ Cause: Resource aging
    ‚Ä¢ Solution: Refresh/replacement
    ‚Ä¢ Prevention: MaxLifetime setting
    
    Thrashing:
    ‚Ä¢ Symptom: Frequent grow/shrink
    ‚Ä¢ Cause: Improper sizing
    ‚Ä¢ Solution: Tune min/max sizes
    ‚Ä¢ Prevention: Workload analysis
    
    Pool Tuning Guidelines:
    
    Database Connection Pool:
    ‚Ä¢ Size: (core_count * 2) + effective_spindle_count
    ‚Ä¢ HikariCP formula for optimal sizing
    ‚Ä¢ Consider query duration
    ‚Ä¢ Monitor active connections
    
    Thread Pool:
    ‚Ä¢ CPU-bound: core_count + 1
    ‚Ä¢ I/O-bound: core_count * (1 + wait_time/service_time)
    ‚Ä¢ Consider task characteristics
    ‚Ä¢ Use fixed or cached pool
    
    HTTP Connection Pool:
    ‚Ä¢ Per-route max: 20-50
    ‚Ä¢ Total max: 200-500
    ‚Ä¢ Keep-alive: 30-60 seconds
    ‚Ä¢ Timeout: 5-30 seconds
    
    Best Practices:
    
    Design:
    ‚Ä¢ Use proven pool libraries
    ‚Ä¢ Configure appropriate sizes
    ‚Ä¢ Implement health checks
    ‚Ä¢ Handle resource cleanup
    ‚Ä¢ Use try-with-resources
    
    Monitoring:
    ‚Ä¢ Track pool metrics
    ‚Ä¢ Set up alerts
    ‚Ä¢ Monitor growth patterns
    ‚Ä¢ Analyze wait times
    ‚Ä¢ Review error logs
    
    Maintenance:
    ‚Ä¢ Regular health checks
    ‚Ä¢ Automatic resource refresh
    ‚Ä¢ Connection validation
    ‚Ä¢ Leak detection
    ‚Ä¢ Performance profiling
    
    Testing:
    ‚Ä¢ Load testing
    ‚Ä¢ Stress testing
    ‚Ä¢ Resource leak detection
    ‚Ä¢ Failure scenario testing
    ‚Ä¢ Timeout testing
    
    When to Use Resource Pooling:
    
    ‚úÖ Good Fit:
    ‚Ä¢ Expensive resource creation
    ‚Ä¢ Frequent resource usage
    ‚Ä¢ Limited resource availability
    ‚Ä¢ Performance critical paths
    ‚Ä¢ High concurrency
    
    ‚ùå Not Recommended:
    ‚Ä¢ Cheap resource creation
    ‚Ä¢ Infrequent usage
    ‚Ä¢ No resource constraints
    ‚Ä¢ Simple use cases
    ‚Ä¢ Low concurrency
    
    Key Insight:
    Resource pooling improves performance by reusing expensive
    resources instead of creating new ones. Essential for database
    connections, threads, and network connections. Proper sizing
    and monitoring are critical for optimal performance.
    """
    
    return {
        "messages": [AIMessage(content=f"üìä Pool Monitor:\n{summary}")]
    }


# Build the graph
def build_resource_pool_graph():
    """Build the resource pooling pattern graph"""
    workflow = StateGraph(ResourcePoolState)
    
    workflow.add_node("pool_mgr", pool_manager)
    workflow.add_node("allocator", resource_allocator)
    workflow.add_node("health", health_monitor)
    workflow.add_node("monitor", pool_monitor)
    
    workflow.add_edge(START, "pool_mgr")
    workflow.add_edge("pool_mgr", "allocator")
    workflow.add_edge("allocator", "health")
    workflow.add_edge("health", "monitor")
    workflow.add_edge("monitor", END)
    
    return workflow.compile()


# Example usage
if __name__ == "__main__":
    graph = build_resource_pool_graph()
    
    print("=== Resource Pooling MCP Pattern ===\n")
    
    # Test Case 1: Database connection pool
    print("\n" + "="*70)
    print("TEST CASE 1: Database Connection Pool")
    print("="*70)
    
    state1 = {
        "messages": [],
        "pool_name": "db_connection_pool",
        "resource_type": "database",
        "pool_size": 0,
        "min_pool_size": 5,
        "max_pool_size": 20,
        "available_resources": 0,
        "in_use_resources": 0,
        "resource_requests": 8,
        "pool_utilization": 0.0,
        "resource_health": {},
        "wait_time": 0.0,
        "allocation_strategy": "fifo"
    }
    
    result1 = graph.invoke(state1)
    
    for msg in result1["messages"]:
        print(f"\n{msg.content}")
        print("-" * 70)
    
    print(f"\nPool Size: {result1.get('pool_size')}")
    print(f"Available: {result1.get('available_resources')}")
    print(f"In Use: {result1.get('in_use_resources')}")
    print(f"Utilization: {result1.get('pool_utilization', 0):.1%}")
    
    # Test Case 2: Thread pool with high demand
    print("\n\n" + "="*70)
    print("TEST CASE 2: Thread Pool (High Demand)")
    print("="*70)
    
    state2 = {
        "messages": [],
        "pool_name": "worker_thread_pool",
        "resource_type": "thread",
        "pool_size": 0,
        "min_pool_size": 10,
        "max_pool_size": 50,
        "available_resources": 0,
        "in_use_resources": 0,
        "resource_requests": 45,  # High demand
        "pool_utilization": 0.0,
        "resource_health": {},
        "wait_time": 0.0,
        "allocation_strategy": "least_used"
    }
    
    result2 = graph.invoke(state2)
    
    print(f"\nPool: {state2['pool_name']}")
    print(f"Resource Type: {state2['resource_type']}")
    print(f"Requests: {state2['resource_requests']}")
    print(f"Pool Size: {result2.get('pool_size')}")
    print(f"Utilization: {result2.get('pool_utilization', 0):.1%}")
    print(f"Wait Time: {result2.get('wait_time', 0):.3f}s")
