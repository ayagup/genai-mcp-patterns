"""
Tracing MCP Pattern

This pattern implements distributed tracing to track requests across
multiple services and identify performance bottlenecks.

Key Features:
- Distributed request tracing
- Span collection and correlation
- Trace assembly and visualization
- Performance bottleneck detection
- Service dependency mapping
"""

from typing import TypedDict, Sequence, Annotated, List, Dict
import operator
import time
import random
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, SystemMessage, AIMessage
from langgraph.graph import StateGraph, START, END


# Define the state
class TracingState(TypedDict):
    """State for tracing pattern"""
    messages: Annotated[Sequence[HumanMessage | SystemMessage | AIMessage], operator.add]
    tracing_backend: str  # "jaeger", "zipkin", "xray", "datadog"
    trace_id: str
    spans: List[Dict]  # [{span_id, parent_span_id, service, operation, duration_ms, tags}]
    services_involved: List[str]
    total_duration_ms: float
    bottlenecks: List[Dict]


# Initialize LLM
llm = ChatOpenAI(model="gpt-4", temperature=0)


# Tracer
def tracer(state: TracingState) -> TracingState:
    """Creates and manages trace spans"""
    tracing_backend = state.get("tracing_backend", "jaeger")
    
    system_message = SystemMessage(content="""You are a distributed tracer.
    Create and track spans across multiple services.""")
    
    user_message = HumanMessage(content=f"""Initialize tracing:

Backend: {tracing_backend}

Set up distributed tracing.""")
    
    response = llm.invoke([system_message, user_message])
    
    # Simulate trace with multiple spans
    import uuid
    trace_id = str(uuid.uuid4())
    
    spans = [
        {
            "span_id": "span-1",
            "parent_span_id": None,
            "service": "api-gateway",
            "operation": "HTTP GET /api/users/123",
            "start_time": int(time.time() * 1000),
            "duration_ms": 245.5,
            "tags": {"http.method": "GET", "http.status_code": 200, "http.url": "/api/users/123"}
        },
        {
            "span_id": "span-2",
            "parent_span_id": "span-1",
            "service": "auth-service",
            "operation": "validateToken",
            "start_time": int(time.time() * 1000) + 5,
            "duration_ms": 15.2,
            "tags": {"auth.user_id": "123", "auth.method": "jwt"}
        },
        {
            "span_id": "span-3",
            "parent_span_id": "span-1",
            "service": "user-service",
            "operation": "getUserById",
            "start_time": int(time.time() * 1000) + 25,
            "duration_ms": 180.3,
            "tags": {"db.system": "postgresql", "db.statement": "SELECT * FROM users WHERE id=?"}
        },
        {
            "span_id": "span-4",
            "parent_span_id": "span-3",
            "service": "database",
            "operation": "SELECT query",
            "start_time": int(time.time() * 1000) + 30,
            "duration_ms": 165.8,
            "tags": {"db.type": "sql", "db.instance": "users-db"}
        },
        {
            "span_id": "span-5",
            "parent_span_id": "span-1",
            "service": "cache-service",
            "operation": "get",
            "start_time": int(time.time() * 1000) + 220,
            "duration_ms": 2.1,
            "tags": {"cache.key": "user:123", "cache.hit": "true"}
        }
    ]
    
    services_involved = list(set(span["service"] for span in spans))
    total_duration_ms = max(span["start_time"] + span["duration_ms"] for span in spans) - min(span["start_time"] for span in spans)
    
    report = f"""
    ðŸ” Distributed Tracing:
    
    Trace Overview:
    â€¢ Trace ID: {trace_id[:8]}...
    â€¢ Backend: {tracing_backend.upper()}
    â€¢ Total Spans: {len(spans)}
    â€¢ Services: {len(services_involved)}
    â€¢ Total Duration: {total_duration_ms:.2f}ms
    
    Distributed Tracing Concepts:
    
    Trace:
    â€¢ End-to-end request journey
    â€¢ Unique trace ID
    â€¢ Multiple spans
    â€¢ Service dependencies
    â€¢ Performance view
    
    Span:
    â€¢ Single operation unit
    â€¢ Unique span ID
    â€¢ Parent-child relationship
    â€¢ Start time + duration
    â€¢ Tags and logs
    â€¢ Service name
    
    Context Propagation:
    â€¢ Trace context in headers
    â€¢ W3C Trace Context standard
    â€¢ traceparent header
    â€¢ tracestate header
    â€¢ Baggage items
    
    Tracing Backends:
    
    Jaeger (CNCF):
    â€¢ OpenTelemetry compatible
    â€¢ Uber origin
    â€¢ Service dependency graph
    â€¢ Root cause analysis
    â€¢ Adaptive sampling
    
    Zipkin:
    â€¢ Twitter origin
    â€¢ Simple architecture
    â€¢ Multiple transports
    â€¢ B3 propagation
    â€¢ Web UI
    
    AWS X-Ray:
    â€¢ AWS native
    â€¢ Service map
    â€¢ Trace analytics
    â€¢ Lambda integration
    â€¢ Sampling rules
    
    Datadog APM:
    â€¢ Full observability
    â€¢ Auto-instrumentation
    â€¢ Service catalog
    â€¢ Analytics
    â€¢ Alerting
    
    OpenTelemetry:
    â€¢ Vendor-neutral standard
    â€¢ Traces, metrics, logs
    â€¢ Auto-instrumentation
    â€¢ Multiple exporters
    â€¢ CNCF graduated
    
    Span Types:
    
    Client Span:
    â€¢ Outbound RPC call
    â€¢ HTTP request
    â€¢ Database query
    â€¢ Cache lookup
    
    Server Span:
    â€¢ Inbound RPC
    â€¢ HTTP handler
    â€¢ Message consumer
    â€¢ Service entry
    
    Internal Span:
    â€¢ Function call
    â€¢ Business logic
    â€¢ Computation
    â€¢ Internal operation
    
    Instrumentation:
    
    Automatic (Python):
    ```python
    from opentelemetry import trace
    from opentelemetry.instrumentation.flask import FlaskInstrumentor
    from opentelemetry.sdk.trace import TracerProvider
    from opentelemetry.sdk.trace.export import BatchSpanProcessor
    from opentelemetry.exporter.jaeger.thrift import JaegerExporter
    
    # Setup
    trace.set_tracer_provider(TracerProvider())
    jaeger_exporter = JaegerExporter(
        agent_host_name="localhost",
        agent_port=6831
    )
    trace.get_tracer_provider().add_span_processor(
        BatchSpanProcessor(jaeger_exporter)
    )
    
    # Auto-instrument Flask
    FlaskInstrumentor().instrument_app(app)
    ```
    
    Manual (Python):
    ```python
    from opentelemetry import trace
    
    tracer = trace.get_tracer(__name__)
    
    with tracer.start_as_current_span("operation") as span:
        span.set_attribute("user.id", "123")
        span.add_event("Processing started")
        
        # Do work
        result = process_data()
        
        span.set_attribute("result.count", len(result))
    ```
    
    Context Propagation (HTTP):
    ```python
    # Inject trace context into headers
    from opentelemetry.propagate import inject
    
    headers = {{}}
    inject(headers)
    response = requests.get(url, headers=headers)
    
    # Extract trace context from headers
    from opentelemetry.propagate import extract
    
    ctx = extract(request.headers)
    with tracer.start_as_current_span("handler", context=ctx):
        handle_request()
    ```
    
    Trace Sampling:
    
    Always Sample:
    â€¢ All traces collected
    â€¢ High overhead
    â€¢ Complete visibility
    â€¢ Expensive at scale
    
    Probabilistic:
    â€¢ Sample N% of traces
    â€¢ Consistent sampling
    â€¢ Scalable
    â€¢ May miss rare issues
    
    Rate Limiting:
    â€¢ Max traces per second
    â€¢ Prevents overload
    â€¢ Predictable cost
    â€¢ May miss bursts
    
    Adaptive:
    â€¢ Adjust based on load
    â€¢ Always sample errors
    â€¢ Increase for slow requests
    â€¢ ML-driven decisions
    
    Tags and Annotations:
    
    Standard Tags:
    â€¢ span.kind: client/server/producer/consumer
    â€¢ component: framework/library name
    â€¢ error: true/false
    â€¢ http.method: GET/POST/etc
    â€¢ http.status_code: 200/404/etc
    â€¢ db.system: postgresql/mongodb
    â€¢ messaging.system: kafka/rabbitmq
    """
    
    return {
        "messages": [AIMessage(content=f"ðŸ” Tracer:\n{response.content}\n{report}")],
        "trace_id": trace_id,
        "spans": spans,
        "services_involved": services_involved,
        "total_duration_ms": total_duration_ms
    }


# Trace Analyzer
def trace_analyzer(state: TracingState) -> TracingState:
    """Analyzes traces to find bottlenecks"""
    spans = state.get("spans", [])
    total_duration_ms = state.get("total_duration_ms", 0.0)
    
    system_message = SystemMessage(content="""You are a trace analyzer.
    Identify performance bottlenecks and optimization opportunities.""")
    
    user_message = HumanMessage(content=f"""Analyze trace:

Total Spans: {len(spans)}
Duration: {total_duration_ms:.2f}ms

Identify bottlenecks.""")
    
    response = llm.invoke([system_message, user_message])
    
    # Identify bottlenecks (spans taking > 50% of total time)
    bottlenecks = []
    for span in spans:
        if span["duration_ms"] > total_duration_ms * 0.5:
            bottlenecks.append({
                "service": span["service"],
                "operation": span["operation"],
                "duration_ms": span["duration_ms"],
                "percentage": (span["duration_ms"] / total_duration_ms * 100)
            })
    
    summary = f"""
    ðŸ“Š TRACING COMPLETE
    
    Trace Analysis:
    â€¢ Trace ID: {state.get('trace_id', 'N/A')[:8]}...
    â€¢ Total Spans: {len(spans)}
    â€¢ Services: {len(state.get('services_involved', []))}
    â€¢ Total Duration: {total_duration_ms:.2f}ms
    â€¢ Bottlenecks Found: {len(bottlenecks)}
    
    {chr(10).join(f"â€¢ {b['service']} - {b['operation']}: {b['duration_ms']:.2f}ms ({b['percentage']:.1f}%)" for b in bottlenecks) if bottlenecks else "â€¢ No major bottlenecks detected"}
    
    Tracing Pattern Process:
    1. Tracer â†’ Create and collect spans
    2. Trace Analyzer â†’ Identify bottlenecks
    
    Trace Visualization:
    
    Waterfall View:
    ```
    api-gateway [HTTP GET]          |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 245ms
      â”œâ”€ auth-service [validate]    |â–ˆ|               15ms
      â”œâ”€ user-service [getUserById] |    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 180ms
      â”‚   â””â”€ database [SELECT]      |     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 165ms
      â””â”€ cache-service [get]        |               â–ˆ| 2ms
    ```
    
    Service Graph:
    ```
    [api-gateway] â†’ [auth-service]
                  â†’ [user-service] â†’ [database]
                  â†’ [cache-service]
    ```
    
    Use Cases:
    
    Performance Debugging:
    â€¢ Identify slow services
    â€¢ Find N+1 query problems
    â€¢ Detect serial processing
    â€¢ Optimize critical paths
    
    Dependency Analysis:
    â€¢ Service dependencies
    â€¢ Call patterns
    â€¢ Circular dependencies
    â€¢ Coupling detection
    
    Error Tracking:
    â€¢ Error propagation
    â€¢ Failure points
    â€¢ Cascading failures
    â€¢ Root cause analysis
    
    Capacity Planning:
    â€¢ Service load
    â€¢ Resource usage
    â€¢ Scaling needs
    â€¢ Cost optimization
    
    Best Practices:
    
    Instrumentation:
    â€¢ Instrument at boundaries
    â€¢ Add business context
    â€¢ Include error details
    â€¢ Avoid sensitive data
    
    Sampling:
    â€¢ Always trace errors
    â€¢ Sample high-traffic paths
    â€¢ Adjust based on volume
    â€¢ Monitor sampling rate
    
    Performance:
    â€¢ Async span export
    â€¢ Batch processing
    â€¢ Resource limits
    â€¢ Sampling strategies
    
    Privacy:
    â€¢ Redact PII
    â€¢ Filter sensitive headers
    â€¢ Compliance requirements
    â€¢ Data retention policies
    
    Key Insight:
    Distributed tracing provides end-to-end visibility
    across microservices, enabling rapid troubleshooting
    and performance optimization.
    """
    
    return {
        "messages": [AIMessage(content=f"ðŸ“Š Trace Analyzer:\n{response.content}\n{summary}")],
        "bottlenecks": bottlenecks
    }


# Build the graph
def build_tracing_graph():
    """Build the tracing pattern graph"""
    workflow = StateGraph(TracingState)
    
    workflow.add_node("tracer", tracer)
    workflow.add_node("analyzer", trace_analyzer)
    
    workflow.add_edge(START, "tracer")
    workflow.add_edge("tracer", "analyzer")
    workflow.add_edge("analyzer", END)
    
    return workflow.compile()


# Example usage
if __name__ == "__main__":
    graph = build_tracing_graph()
    
    print("=== Tracing MCP Pattern ===\n")
    
    # Test Case: Distributed request tracing
    print("\n" + "="*70)
    print("TEST CASE: Multi-Service Request Trace")
    print("="*70)
    
    state = {
        "messages": [],
        "tracing_backend": "jaeger",
        "trace_id": "",
        "spans": [],
        "services_involved": [],
        "total_duration_ms": 0.0,
        "bottlenecks": []
    }
    
    result = graph.invoke(state)
    
    for msg in result["messages"]:
        print(f"\n{msg.content}")
        print("-" * 70)
    
    print(f"\nTrace ID: {result.get('trace_id', 'N/A')[:16]}...")
    print(f"Total Spans: {len(result.get('spans', []))}")
    print(f"Services: {len(result.get('services_involved', []))}")
    print(f"Bottlenecks: {len(result.get('bottlenecks', []))}")
