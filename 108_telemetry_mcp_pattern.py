"""
Telemetry MCP Pattern

This pattern implements comprehensive telemetry collection across
distributed systems for observability and monitoring.

Key Features:
- Multi-source telemetry collection
- Metrics, logs, and traces integration
- Real-time data aggregation
- Telemetry export and storage
- Observability correlation
"""

from typing import TypedDict, Sequence, Annotated, List, Dict
import operator
import time
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, SystemMessage, AIMessage
from langgraph.graph import StateGraph, START, END


# Define the state
class TelemetryState(TypedDict):
    """State for telemetry pattern"""
    messages: Annotated[Sequence[HumanMessage | SystemMessage | AIMessage], operator.add]
    telemetry_data: Dict  # {metrics, logs, traces, events}
    sources: List[str]
    collection_interval_seconds: int
    exporters: List[str]  # ["prometheus", "jaeger", "elasticsearch"]
    correlation_data: Dict


# Initialize LLM
llm = ChatOpenAI(model="gpt-4", temperature=0)


# Telemetry Collector
def telemetry_collector(state: TelemetryState) -> TelemetryState:
    """Collects telemetry from multiple sources"""
    sources = state.get("sources", [])
    
    system_message = SystemMessage(content="""You are a telemetry collector.
    Gather metrics, logs, and traces from distributed systems.""")
    
    user_message = HumanMessage(content=f"""Collect telemetry:

Sources: {len(sources) if sources else 'Auto-discover'}

Initialize telemetry collection.""")
    
    response = llm.invoke([system_message, user_message])
    
    # Define sources if not provided
    if not sources:
        sources = ["api-gateway", "user-service", "database", "cache", "message-queue"]
    
    # Collect comprehensive telemetry
    current_time = int(time.time())
    
    telemetry_data = {
        "metrics": {
            "api-gateway": {
                "http_requests_total": 15234,
                "http_request_duration_seconds": {"p50": 0.045, "p95": 0.125, "p99": 0.342},
                "http_errors_total": 87,
                "active_connections": 234
            },
            "user-service": {
                "rpc_calls_total": 8934,
                "rpc_duration_seconds": {"p50": 0.023, "p95": 0.089, "p99": 0.234},
                "cpu_usage_percent": 67.5,
                "memory_usage_mb": 512.3
            },
            "database": {
                "query_duration_seconds": {"p50": 0.012, "p95": 0.056, "p99": 0.145},
                "active_connections": 45,
                "connection_pool_usage_percent": 75.0,
                "slow_queries_total": 12
            }
        },
        "logs": [
            {
                "timestamp": current_time,
                "level": "ERROR",
                "source": "api-gateway",
                "message": "Failed to connect to user-service",
                "trace_id": "abc123",
                "span_id": "span-1"
            },
            {
                "timestamp": current_time + 10,
                "level": "WARN",
                "source": "database",
                "message": "High connection pool utilization",
                "trace_id": None,
                "span_id": None
            }
        ],
        "traces": [
            {
                "trace_id": "abc123",
                "spans": [
                    {"span_id": "span-1", "service": "api-gateway", "duration_ms": 245},
                    {"span_id": "span-2", "service": "user-service", "duration_ms": 180},
                    {"span_id": "span-3", "service": "database", "duration_ms": 165}
                ],
                "total_duration_ms": 245
            }
        ],
        "events": [
            {
                "timestamp": current_time,
                "type": "deployment",
                "source": "ci-cd",
                "message": "Deployed version 1.2.3 to production",
                "metadata": {"version": "1.2.3", "environment": "production"}
            }
        ]
    }
    
    exporters = ["prometheus", "jaeger", "elasticsearch", "datadog"]
    collection_interval = 15
    
    report = f"""
    ðŸ“¡ Telemetry Collector:
    
    Collection Overview:
    â€¢ Sources: {len(sources)}
    â€¢ Metrics Collected: {sum(len(v) for v in telemetry_data['metrics'].values())}
    â€¢ Log Entries: {len(telemetry_data['logs'])}
    â€¢ Traces: {len(telemetry_data['traces'])}
    â€¢ Events: {len(telemetry_data['events'])}
    â€¢ Interval: {collection_interval}s
    
    Telemetry Concepts:
    
    Three Pillars of Observability:
    
    Metrics:
    â€¢ Quantitative measurements
    â€¢ Time-series data
    â€¢ Aggregatable
    â€¢ Low cardinality
    â€¢ Examples: CPU %, request rate, error count
    
    Logs:
    â€¢ Discrete events
    â€¢ Detailed context
    â€¢ High cardinality
    â€¢ Searchable
    â€¢ Examples: Errors, warnings, audit trail
    
    Traces:
    â€¢ Request flow
    â€¢ Service dependencies
    â€¢ Timing breakdown
    â€¢ Distributed context
    â€¢ Examples: End-to-end request path
    
    Additional Signals:
    
    Events:
    â€¢ State changes
    â€¢ Deployments
    â€¢ Configuration changes
    â€¢ Infrastructure events
    â€¢ Business events
    
    Profiles:
    â€¢ CPU flamegraphs
    â€¢ Memory allocation
    â€¢ Continuous profiling
    â€¢ Code-level performance
    
    OpenTelemetry:
    
    Overview:
    â€¢ Vendor-neutral standard
    â€¢ CNCF graduated project
    â€¢ Single SDK for all signals
    â€¢ Auto-instrumentation
    â€¢ Multiple exporters
    
    Components:
    â€¢ API: Instrumentation interface
    â€¢ SDK: Implementation
    â€¢ Collector: Processing pipeline
    â€¢ Exporters: Backend integration
    
    Python Example:
    ```python
    from opentelemetry import trace, metrics
    from opentelemetry.sdk.trace import TracerProvider
    from opentelemetry.sdk.metrics import MeterProvider
    from opentelemetry.sdk.resources import Resource
    from opentelemetry.exporter.otlp.proto.grpc.trace_exporter import OTLPSpanExporter
    from opentelemetry.exporter.otlp.proto.grpc.metric_exporter import OTLPMetricExporter
    
    # Setup resource (service identification)
    resource = Resource(attributes={{
        "service.name": "my-service",
        "service.version": "1.2.3",
        "deployment.environment": "production"
    }})
    
    # Setup tracing
    trace.set_tracer_provider(TracerProvider(resource=resource))
    tracer = trace.get_tracer(__name__)
    
    # Setup span exporter
    span_exporter = OTLPSpanExporter(endpoint="http://collector:4317")
    trace.get_tracer_provider().add_span_processor(
        BatchSpanProcessor(span_exporter)
    )
    
    # Setup metrics
    metrics.set_meter_provider(MeterProvider(resource=resource))
    meter = metrics.get_meter(__name__)
    
    # Create metrics
    request_counter = meter.create_counter(
        "http_requests_total",
        description="Total HTTP requests"
    )
    
    request_duration = meter.create_histogram(
        "http_request_duration_seconds",
        description="HTTP request duration"
    )
    
    # Use in application
    @tracer.start_as_current_span("process_request")
    def process_request(request):
        request_counter.add(1, {{"method": request.method}})
        
        start = time.time()
        result = handle_request(request)
        duration = time.time() - start
        
        request_duration.record(duration, {{"endpoint": request.path}})
        
        return result
    ```
    
    Telemetry Collection Patterns:
    
    Push-based:
    â€¢ Application pushes data
    â€¢ StatsD, OTLP
    â€¢ Fire-and-forget
    â€¢ Good for short-lived processes
    
    Pull-based:
    â€¢ Collector scrapes endpoints
    â€¢ Prometheus /metrics
    â€¢ Service discovery
    â€¢ Good for long-lived services
    
    Agent-based:
    â€¢ Sidecar collector
    â€¢ DaemonSet (Kubernetes)
    â€¢ Local aggregation
    â€¢ Reduced network traffic
    
    Telemetry Pipeline:
    
    Collection â†’ Processing â†’ Export â†’ Storage â†’ Visualization
    
    Processing Steps:
    â€¢ Filtering: Remove noise
    â€¢ Sampling: Reduce volume
    â€¢ Enrichment: Add context
    â€¢ Aggregation: Summarize data
    â€¢ Correlation: Link signals
    
    OpenTelemetry Collector:
    ```yaml
    receivers:
      otlp:
        protocols:
          grpc:
            endpoint: 0.0.0.0:4317
          http:
            endpoint: 0.0.0.0:4318
      
      prometheus:
        config:
          scrape_configs:
          - job_name: 'services'
            scrape_interval: 15s
            static_configs:
            - targets: ['service:8080']
    
    processors:
      batch:
        timeout: 10s
        send_batch_size: 1024
      
      attributes:
        actions:
        - key: environment
          value: production
          action: insert
      
      resource:
        attributes:
        - key: cluster
          value: us-west-2
          action: insert
    
    exporters:
      prometheus:
        endpoint: "0.0.0.0:8889"
      
      jaeger:
        endpoint: "jaeger:14250"
        tls:
          insecure: true
      
      elasticsearch:
        endpoints: ["http://elasticsearch:9200"]
        index: "telemetry"
      
      otlp:
        endpoint: "backend:4317"
    
    service:
      pipelines:
        traces:
          receivers: [otlp]
          processors: [batch, attributes]
          exporters: [jaeger, otlp]
        
        metrics:
          receivers: [otlp, prometheus]
          processors: [batch, resource]
          exporters: [prometheus, otlp]
        
        logs:
          receivers: [otlp]
          processors: [batch, attributes]
          exporters: [elasticsearch]
    ```
    
    Sampling Strategies:
    
    Head Sampling (Before trace complete):
    â€¢ Probabilistic: Sample N%
    â€¢ Rate limiting: Max traces/sec
    â€¢ Always sample errors
    â€¢ Deterministic across services
    
    Tail Sampling (After trace complete):
    â€¢ Sample based on full context
    â€¢ Keep slow requests
    â€¢ Keep errors
    â€¢ Smart sampling decisions
    â€¢ Higher resource cost
    """
    
    return {
        "messages": [AIMessage(content=f"ðŸ“¡ Telemetry Collector:\n{response.content}\n{report}")],
        "telemetry_data": telemetry_data,
        "sources": sources,
        "collection_interval_seconds": collection_interval,
        "exporters": exporters
    }


# Correlation Engine
def correlation_engine(state: TelemetryState) -> TelemetryState:
    """Correlates metrics, logs, and traces"""
    telemetry_data = state.get("telemetry_data", {})
    
    system_message = SystemMessage(content="""You are a correlation engine.
    Link metrics, logs, and traces to provide unified observability.""")
    
    user_message = HumanMessage(content=f"""Correlate telemetry:

Metrics: {len(telemetry_data.get('metrics', {}))}
Logs: {len(telemetry_data.get('logs', []))}
Traces: {len(telemetry_data.get('traces', []))}

Build correlation map.""")
    
    response = llm.invoke([system_message, user_message])
    
    # Build correlation data
    correlation_data = {
        "trace_log_correlation": {},
        "metric_trace_correlation": {},
        "anomaly_correlation": []
    }
    
    # Correlate logs with traces
    for log in telemetry_data.get("logs", []):
        if log.get("trace_id"):
            if log["trace_id"] not in correlation_data["trace_log_correlation"]:
                correlation_data["trace_log_correlation"][log["trace_id"]] = []
            correlation_data["trace_log_correlation"][log["trace_id"]].append(log)
    
    # Detect correlated anomalies
    metrics = telemetry_data.get("metrics", {})
    if metrics.get("api-gateway", {}).get("http_errors_total", 0) > 50:
        correlation_data["anomaly_correlation"].append({
            "type": "high_error_rate",
            "source": "api-gateway",
            "metric": "http_errors_total",
            "value": metrics["api-gateway"]["http_errors_total"],
            "related_logs": [log for log in telemetry_data.get("logs", []) if log["source"] == "api-gateway"]
        })
    
    summary = f"""
    ðŸ“Š TELEMETRY COMPLETE
    
    Telemetry Summary:
    â€¢ Sources: {len(state.get('sources', []))}
    â€¢ Metrics Categories: {len(telemetry_data.get('metrics', {}))}
    â€¢ Log Entries: {len(telemetry_data.get('logs', []))}
    â€¢ Traces: {len(telemetry_data.get('traces', []))}
    â€¢ Events: {len(telemetry_data.get('events', []))}
    â€¢ Exporters: {len(state.get('exporters', []))}
    
    Correlations Found:
    â€¢ Trace-Log Links: {len(correlation_data['trace_log_correlation'])}
    â€¢ Anomalies: {len(correlation_data['anomaly_correlation'])}
    
    Telemetry Pattern Process:
    1. Telemetry Collector â†’ Gather all signals
    2. Correlation Engine â†’ Link related data
    
    Correlation Benefits:
    
    Unified View:
    â€¢ Single pane of glass
    â€¢ Context switching reduced
    â€¢ Faster troubleshooting
    â€¢ Better insights
    
    Root Cause Analysis:
    â€¢ Error logs â†’ traces
    â€¢ Slow requests â†’ metrics
    â€¢ Anomalies â†’ events
    â€¢ Full context
    
    Correlation Techniques:
    
    Trace ID Propagation:
    â€¢ Generate at entry point
    â€¢ Pass in headers (traceparent)
    â€¢ Include in all logs
    â€¢ Link spans to logs
    
    Temporal Correlation:
    â€¢ Time window matching
    â€¢ Before/after analysis
    â€¢ Event causation
    â€¢ Pattern detection
    
    Service Correlation:
    â€¢ Service dependency graph
    â€¢ Cross-service analysis
    â€¢ Cascade detection
    â€¢ Impact radius
    
    Metadata Correlation:
    â€¢ User ID
    â€¢ Session ID
    â€¢ Request ID
    â€¢ Custom attributes
    
    Telemetry Best Practices:
    
    Standardization:
    â€¢ Consistent naming
    â€¢ Common labels
    â€¢ Standard formats
    â€¢ Schema validation
    
    Context Propagation:
    â€¢ W3C Trace Context
    â€¢ Baggage for metadata
    â€¢ Consistent IDs
    â€¢ Cross-service correlation
    
    Resource Attribution:
    â€¢ Service name
    â€¢ Version
    â€¢ Environment
    â€¢ Cluster/region
    
    Cardinality Control:
    â€¢ Limit label values
    â€¢ Avoid high-cardinality IDs
    â€¢ Use exemplars
    â€¢ Smart sampling
    
    Privacy and Security:
    â€¢ Redact PII
    â€¢ Encrypt in transit
    â€¢ Access controls
    â€¢ Retention policies
    
    Cost Optimization:
    â€¢ Sampling strategies
    â€¢ Data retention tiers
    â€¢ Aggregation
    â€¢ Efficient storage
    
    Key Insight:
    Comprehensive telemetry with correlation across
    metrics, logs, and traces provides deep system
    understanding and enables rapid issue resolution.
    """
    
    return {
        "messages": [AIMessage(content=f"ðŸ”— Correlation Engine:\n{response.content}\n{summary}")],
        "correlation_data": correlation_data
    }


# Build the graph
def build_telemetry_graph():
    """Build the telemetry pattern graph"""
    workflow = StateGraph(TelemetryState)
    
    workflow.add_node("telemetry_collector", telemetry_collector)
    workflow.add_node("correlation_engine", correlation_engine)
    
    workflow.add_edge(START, "telemetry_collector")
    workflow.add_edge("telemetry_collector", "correlation_engine")
    workflow.add_edge("correlation_engine", END)
    
    return workflow.compile()


# Example usage
if __name__ == "__main__":
    graph = build_telemetry_graph()
    
    print("=== Telemetry MCP Pattern ===\n")
    
    # Test Case: Comprehensive telemetry collection
    print("\n" + "="*70)
    print("TEST CASE: Multi-Signal Telemetry Collection")
    print("="*70)
    
    state = {
        "messages": [],
        "telemetry_data": {},
        "sources": [],
        "collection_interval_seconds": 15,
        "exporters": [],
        "correlation_data": {}
    }
    
    result = graph.invoke(state)
    
    for msg in result["messages"]:
        print(f"\n{msg.content}")
        print("-" * 70)
    
    print(f"\nTelemetry Results:")
    print(f"Sources: {len(result.get('sources', []))}")
    print(f"Metrics: {len(result.get('telemetry_data', {}).get('metrics', {}))}")
    print(f"Logs: {len(result.get('telemetry_data', {}).get('logs', []))}")
    print(f"Traces: {len(result.get('telemetry_data', {}).get('traces', []))}")
