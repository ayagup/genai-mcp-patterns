"""
ReAct MCP Pattern (Reasoning + Acting)

This pattern implements the ReAct paradigm where the model alternates between
reasoning about the problem and taking actions (using tools) to gather information.

Key Features:
- Reasoning and acting interleaved
- Tool usage integration
- Observation processing
- Iterative problem solving
- Dynamic action selection
"""

from typing import TypedDict, Sequence, Annotated, List, Dict
import operator
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, SystemMessage, AIMessage
from langgraph.graph import StateGraph, START, END


# Define the state
class ReActState(TypedDict):
    """State for ReAct pattern"""
    messages: Annotated[Sequence[HumanMessage | SystemMessage | AIMessage], operator.add]
    task: str
    reasoning_trace: List[str]
    actions_taken: List[Dict]
    observations: List[str]
    max_iterations: int
    current_iteration: int
    task_complete: bool
    final_answer: str


# Initialize LLM
llm = ChatOpenAI(model="gpt-4", temperature=0.2)


# Reasoning Agent
def reasoning_agent(state: ReActState) -> ReActState:
    """Generates reasoning and decides next action"""
    task = state.get("task", "")
    actions_taken = state.get("actions_taken", [])
    observations = state.get("observations", [])
    current_iteration = state.get("current_iteration", 0)
    
    # Build context from previous actions and observations
    context = ""
    if actions_taken and observations:
        for i, (action, obs) in enumerate(zip(actions_taken, observations)):
            context += f"\nStep {i+1}:\n"
            context += f"Thought: {action.get('reasoning', '')}\n"
            context += f"Action: {action.get('action', '')} ({action.get('tool', '')})\n"
            context += f"Observation: {obs}\n"
    
    system_prompt = """You are a ReAct agent that reasons and acts iteratively.

For each step, follow this format:
Thought: [your reasoning about what to do next]
Action: [the action to take]
Tool: [which tool to use: search, calculate, lookup, or final_answer]
Action Input: [input for the tool]

Available Tools:
- search: Search for information online
- calculate: Perform calculations
- lookup: Look up specific facts
- final_answer: Provide final answer when task is complete

Keep iterating until you can provide a final answer."""
    
    user_prompt = f"""Task: {task}

{context}

What should we do next? Provide your Thought, Action, Tool, and Action Input."""
    
    messages = [
        SystemMessage(content=system_prompt),
        HumanMessage(content=user_prompt)
    ]
    
    response = llm.invoke(messages)
    content = response.content
    
    # Parse ReAct components
    thought = ""
    action = ""
    tool = ""
    action_input = ""
    
    for line in content.split("\n"):
        if line.startswith("Thought:"):
            thought = line.replace("Thought:", "").strip()
        elif line.startswith("Action:"):
            action = line.replace("Action:", "").strip()
        elif line.startswith("Tool:"):
            tool = line.replace("Tool:", "").strip()
        elif line.startswith("Action Input:"):
            action_input = line.replace("Action Input:", "").strip()
    
    # Record action
    action_dict = {
        "iteration": current_iteration + 1,
        "reasoning": thought,
        "action": action,
        "tool": tool,
        "input": action_input
    }
    
    report = f"""
    ðŸ§  Reasoning Agent (Iteration {current_iteration + 1}):
    
    ReAct Trace:
    â€¢ Task: {task[:100]}...
    â€¢ Current Iteration: {current_iteration + 1}
    â€¢ Actions Taken: {len(actions_taken)}
    
    Current Step:
    Thought: {thought}
    Action: {action}
    Tool: {tool}
    Input: {action_input}
    
    ReAct Framework:
    
    Core Concept:
    Synergize Reasoning and Acting in language models.
    Alternate between thinking and doing.
    
    The ReAct Loop:
    
    1. Thought (Reasoning):
    â€¢ Analyze current situation
    â€¢ Reason about what's needed
    â€¢ Plan next action
    â€¢ Reflect on observations
    
    2. Action (Acting):
    â€¢ Execute tool/action
    â€¢ Gather information
    â€¢ Perform computation
    â€¢ Interact with environment
    
    3. Observation:
    â€¢ Receive action results
    â€¢ Process new information
    â€¢ Update understanding
    â€¢ Inform next reasoning
    
    4. Repeat:
    â€¢ Until task complete
    â€¢ Or max iterations reached
    â€¢ Iterative refinement
    â€¢ Progressive solution
    
    ReAct vs Other Patterns:
    
    ReAct vs Chain-of-Thought:
    â€¢ CoT: Pure reasoning, no actions
    â€¢ ReAct: Reasoning + Actions interleaved
    â€¢ ReAct: Can gather new information
    â€¢ ReAct: Interactive problem solving
    
    ReAct vs Acting-Only:
    â€¢ Acting: Random/scripted actions
    â€¢ ReAct: Reasoned, purposeful actions
    â€¢ ReAct: Explains why each action
    â€¢ ReAct: More interpretable
    
    Benefits of ReAct:
    
    Grounding:
    â€¢ Actions based on reasoning
    â€¢ Reasoning guided by observations
    â€¢ Reduces hallucination
    â€¢ Facts from environment
    
    Interpretability:
    â€¢ See thought process
    â€¢ Understand action choices
    â€¢ Track reasoning trace
    â€¢ Debug errors
    
    Flexibility:
    â€¢ Adapt to observations
    â€¢ Change strategy dynamically
    â€¢ Handle unexpected results
    â€¢ Robust to errors
    
    Reliability:
    â€¢ Verify with actions
    â€¢ Cross-check reasoning
    â€¢ Factual grounding
    â€¢ Error recovery
    
    Tool Integration:
    
    Search Tools:
    â€¢ Web search
    â€¢ Database lookup
    â€¢ API calls
    â€¢ Information retrieval
    
    Computation Tools:
    â€¢ Calculator
    â€¢ Code execution
    â€¢ Data processing
    â€¢ Simulations
    
    Memory Tools:
    â€¢ Store information
    â€¢ Retrieve context
    â€¢ Update knowledge
    â€¢ Long-term memory
    
    Communication Tools:
    â€¢ Ask clarifying questions
    â€¢ Request feedback
    â€¢ Collaborate
    â€¢ Delegate tasks
    
    Research Insights (Yao et al. 2022):
    
    Performance:
    â€¢ Outperforms CoT on QA tasks
    â€¢ 27% â†’ 62% on HotpotQA
    â€¢ Better factual grounding
    â€¢ Reduces errors
    
    Synergy:
    â€¢ Reasoning helps action selection
    â€¢ Actions inform reasoning
    â€¢ Greater than sum of parts
    â€¢ Emergent capabilities
    
    Applications:
    â€¢ Question answering
    â€¢ Fact verification
    â€¢ Interactive tasks
    â€¢ Multi-step reasoning
    
    Previous Steps Summary:
    {chr(10).join(f"  Step {i+1}: {a.get('tool', '')} - {a.get('action', '')[:60]}..." for i, a in enumerate(actions_taken))}
    """
    
    return {
        "messages": [AIMessage(content=f"ðŸ§  Reasoning Agent:\n{report}\n\n{response.content}")],
        "reasoning_trace": state.get("reasoning_trace", []) + [thought],
        "actions_taken": actions_taken + [action_dict],
        "current_iteration": current_iteration + 1
    }


# Action Executor
def action_executor(state: ReActState) -> ReActState:
    """Simulates tool execution and returns observations"""
    actions_taken = state.get("actions_taken", [])
    observations = state.get("observations", [])
    max_iterations = state.get("max_iterations", 5)
    current_iteration = state.get("current_iteration", 0)
    
    if not actions_taken:
        observation = "No action taken yet."
    else:
        last_action = actions_taken[-1]
        tool = last_action.get("tool", "")
        action_input = last_action.get("input", "")
        
        # Simulate tool execution (in real implementation, call actual tools)
        if tool == "final_answer":
            observation = f"Task complete. Final answer: {action_input}"
            task_complete = True
            final_answer = action_input
        elif tool == "search":
            observation = f"[Simulated search results for: {action_input}] - In a real implementation, this would return actual search results."
            task_complete = False
            final_answer = ""
        elif tool == "calculate":
            observation = f"[Simulated calculation for: {action_input}] - In a real implementation, this would perform the calculation."
            task_complete = False
            final_answer = ""
        elif tool == "lookup":
            observation = f"[Simulated lookup for: {action_input}] - In a real implementation, this would retrieve the information."
            task_complete = False
            final_answer = ""
        else:
            observation = f"Unknown tool: {tool}"
            task_complete = False
            final_answer = ""
    
    # Check if we should continue
    task_complete = (
        state.get("task_complete", False) or
        (actions_taken and actions_taken[-1].get("tool") == "final_answer") or
        current_iteration >= max_iterations
    )
    
    final_answer = ""
    if task_complete and actions_taken:
        final_answer = actions_taken[-1].get("input", "")
    
    report = f"""
    ðŸ”§ Action Executor:
    
    Execution Results:
    â€¢ Tool Used: {actions_taken[-1].get('tool', 'none') if actions_taken else 'none'}
    â€¢ Action Input: {actions_taken[-1].get('input', '')[:100] if actions_taken else ''}...
    â€¢ Observation: {observation[:150]}...
    â€¢ Task Complete: {task_complete}
    
    ReAct Tool Patterns:
    
    Tool Types:
    
    Information Gathering:
    â€¢ search(query) â†’ results
    â€¢ lookup(entity) â†’ facts
    â€¢ ask(question) â†’ answer
    â€¢ retrieve(document) â†’ content
    
    Computation:
    â€¢ calculate(expression) â†’ value
    â€¢ execute(code) â†’ output
    â€¢ simulate(scenario) â†’ outcome
    â€¢ process(data) â†’ result
    
    State Modification:
    â€¢ store(key, value) â†’ success
    â€¢ update(item) â†’ status
    â€¢ delete(item) â†’ confirmation
    â€¢ modify(object) â†’ new_state
    
    Communication:
    â€¢ send_message(recipient, msg) â†’ response
    â€¢ request_input(prompt) â†’ user_input
    â€¢ notify(event) â†’ acknowledgment
    â€¢ collaborate(agent, task) â†’ result
    
    Tool Selection Strategies:
    
    Rule-Based:
    â€¢ If-then rules
    â€¢ Pattern matching
    â€¢ Fixed sequences
    â€¢ Deterministic
    
    Learning-Based:
    â€¢ Model predicts tool
    â€¢ Context-aware selection
    â€¢ Adaptive strategy
    â€¢ Optimizes over time
    
    Hybrid:
    â€¢ Combine rules and learning
    â€¢ Fallback mechanisms
    â€¢ Best of both worlds
    â€¢ Robust and flexible
    
    Error Handling in ReAct:
    
    Tool Failures:
    â€¢ Retry with modified input
    â€¢ Try alternative tool
    â€¢ Ask for clarification
    â€¢ Graceful degradation
    
    Invalid Reasoning:
    â€¢ Self-correction
    â€¢ Re-evaluate assumptions
    â€¢ Seek additional info
    â€¢ Backtrack if needed
    
    Incomplete Information:
    â€¢ Identify gaps
    â€¢ Gather more data
    â€¢ Make reasonable assumptions
    â€¢ State uncertainties
    
    Max Iterations:
    â€¢ Provide best effort answer
    â€¢ Explain limitations
    â€¢ Suggest next steps
    â€¢ Partial solutions
    
    Advanced ReAct Techniques:
    
    Self-Ask ReAct:
    â€¢ Ask follow-up questions
    â€¢ Decompose complex queries
    â€¢ Iterative clarification
    â€¢ Deeper understanding
    
    Multi-Agent ReAct:
    â€¢ Multiple agents collaborate
    â€¢ Share observations
    â€¢ Parallel exploration
    â€¢ Faster convergence
    
    Reflexion ReAct:
    â€¢ Reflect on mistakes
    â€¢ Learn from errors
    â€¢ Improve over trials
    â€¢ Meta-learning
    
    Hierarchical ReAct:
    â€¢ High-level planning
    â€¢ Low-level execution
    â€¢ Abstraction layers
    â€¢ Scalable reasoning
    
    ReAct Best Practices:
    
    Prompt Engineering:
    â€¢ Clear thought/action format
    â€¢ List available tools
    â€¢ Provide examples
    â€¢ Specify constraints
    
    Tool Design:
    â€¢ Simple interfaces
    â€¢ Clear descriptions
    â€¢ Reliable execution
    â€¢ Error messages
    
    Iteration Management:
    â€¢ Set max iterations
    â€¢ Early stopping
    â€¢ Progress tracking
    â€¢ Timeout handling
    
    Evaluation:
    â€¢ Task success rate
    â€¢ Steps to solution
    â€¢ Tool usage efficiency
    â€¢ Error recovery
    
    Implementation Tips:
    
    Temperature:
    â€¢ Lower (0.1-0.3) for focused reasoning
    â€¢ Higher for creative exploration
    â€¢ Adjust per task type
    
    Prompt Format:
    ```
    Thought: [reasoning]
    Action: [what to do]
    Tool: [which tool]
    Action Input: [tool input]
    Observation: [result]
    ... (repeat)
    Thought: I now know the final answer
    Final Answer: [answer]
    ```
    
    Current Observation:
    {observation}
    
    Key Insight:
    ReAct creates a synergistic loop between reasoning and
    acting, enabling language models to interact with external
    tools and environments for grounded problem-solving.
    """
    
    return {
        "messages": [AIMessage(content=f"ðŸ”§ Action Executor:\n{report}")],
        "observations": observations + [observation],
        "task_complete": task_complete,
        "final_answer": final_answer
    }


# Build the graph
def build_react_graph():
    """Build the ReAct pattern graph"""
    workflow = StateGraph(ReActState)
    
    workflow.add_node("reasoning_agent", reasoning_agent)
    workflow.add_node("action_executor", action_executor)
    
    # Define conditional routing
    def should_continue(state: ReActState) -> str:
        """Determine if we should continue or end"""
        if state.get("task_complete", False):
            return "end"
        if state.get("current_iteration", 0) >= state.get("max_iterations", 5):
            return "end"
        return "continue"
    
    workflow.add_edge(START, "reasoning_agent")
    workflow.add_edge("reasoning_agent", "action_executor")
    
    # Conditional edge: continue loop or end
    workflow.add_conditional_edges(
        "action_executor",
        should_continue,
        {
            "continue": "reasoning_agent",
            "end": END
        }
    )
    
    return workflow.compile()


# Example usage
if __name__ == "__main__":
    graph = build_react_graph()
    
    print("=== ReAct MCP Pattern ===\n")
    
    # Test Case: Multi-step question answering
    print("\n" + "="*70)
    print("TEST CASE: Interactive Question Answering with ReAct")
    print("="*70)
    
    state = {
        "messages": [],
        "task": "What is the population of the capital city of France?",
        "reasoning_trace": [],
        "actions_taken": [],
        "observations": [],
        "max_iterations": 3,
        "current_iteration": 0,
        "task_complete": False,
        "final_answer": ""
    }
    
    result = graph.invoke(state)
    
    for msg in result["messages"]:
        print(f"\n{msg.content}")
        print("-" * 70)
    
    print(f"\n{'='*70}")
    print("Pattern 125: ReAct (Reasoning + Acting) - COMPLETE")
    print(f"{'='*70}")
